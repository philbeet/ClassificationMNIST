{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this interactive notebook, we will go through examples of different types of classification models, all using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Binary Classification</h1>\n",
    "\n",
    "Part 1 of our exploration-by-project into classification is the easiest. Think of Jian Yangs Hotdog/Not Hotdog!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch_openml() returns a sklearn.utils.Bunch object. This is a dictionary whose entries can also be accessed as attributes. It contains the following entries:\n",
    "\n",
    "* \"DESCR\" - a description of the data\n",
    "* \"data\" - the input data - a 2d numpy array (usually)\n",
    "* \"target\" - the labels, usually a 1d numpy array\n",
    "\n",
    "Usually fetch returns a pandas dataframe, but since our data is images pandas isnt ideal, so we set as frame to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70,000 images with 784 \"features (columns)\". This is because each image is 28*28 pixels (784) and each feature represents one pixel's intensity (from 0-255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_digit(image_data): #img data is a single row of our X array\n",
    "    image = image_data.reshape(28,28) # reshape the array from 1row-784 columns to 28 rows 28 columns - same as og image dimensions\n",
    "    plt.imshow(image, cmap='binary') #show the image and each pixel is either \"on\" or \"off\"\n",
    "    plt.axis('off') #turn off axes\n",
    "\n",
    "plot_digit(X[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The train test split</h1>\n",
    "We can very simply create a train test split for this project because the data is already shuffled for us. \n",
    "\n",
    "Many ML algos are sensitive to the order of the training instances - if they get too many similar instances in a row, they will perform like ass. Shuffling data will help alleviate this.\n",
    "\n",
    "Shuffling is a bad idea for time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our binary classifier will solve  a simple problem : is a digit a 5?\n",
    "\n",
    "Step 1: Let's create the target vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = y_train=='5' #this is a vector that is false for every outcome except 5!\n",
    "y_test_5 = y_test == '5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Problems With Accuracy Scoring</h1>\n",
    "\n",
    "To illustrate how accuracy scoring is not always the best, lets try training a classifier. For our example, we'll use an SGD (Stochastic gradient descent) classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this classifier, we can pass in:\n",
    "\n",
    "`sgd_clf.predict([some_digit])` -> digit must be an array-like object, so you can't just pass (somedigit), it has to be ([some_digit])\n",
    "\n",
    "Let's measure our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96392478, 0.95842129, 0.96117188])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5,\n",
    "                cv=3, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOOP WOOP! You got >95% accuracy on all cross val folds! Wtf??! FIRST TRY!\n",
    "\n",
    "Hold your horses. Now, lets take a look at a dummy classifier that just classifies every image as the most frequent class\n",
    "* in our case, the most frequent class is \"false\", because we are a binary classifier, and only 10% of outcomes are actually 5's (true).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91032365, 0.91031792, 0.91031792])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "\n",
    "cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRUH MOMENT. Just classifing every single image as \"not 5\" gives us 91% accuracy. Again, this is because roughly 10% of the data is 5's, so 90% is not 5.\n",
    "\n",
    "This demonstrates the DANGER of using accuracy-based metrics on skewed datasets (when some classes are more frequent than others). \n",
    "\n",
    "A much better way is to evaluate the performance of a classifier with a confusion matrix.\n",
    "\n",
    "<h1>Confusion Matrices</h1>\n",
    "A confusion matrix counts the number of times class A is classified as class B, for all possible pairs.\n",
    "\n",
    "For example, it will tell us the number of times the classifier confused an 8 with a 0 --> just look at row #8 column #0.\n",
    "\n",
    "to do this, we make predictions and compare them to the actual targets. We don't want to use the test set (only use test set at the end of the project!), we can use SKLearn's **crossvalpredict** function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross val predict performs K-fold cross validation, but instead of returning evaluation scores (like cross val scores), it returns the predictions made by the model on each fold.\n",
    "\n",
    "It returns all of these folds results as a single array. \n",
    "\n",
    "Lets get a confusion matrix. we can import it directly from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41582,  1112],\n",
       "       [  709,  3497]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm= confusion_matrix(y_train_5, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each row represents a class. In our case, we have **non-5** and **5s**.\n",
    "\n",
    "* Each column represents an outcome.\n",
    "\n",
    "For example, the first row represents all non-5s. The first column says that 41,582 were correctly classified as non-5. The second column says 1112 were wrongly classified as 5 (false positive, type I error).\n",
    "\n",
    "The second row is all 5s. 709 were wrongly classified as non-5 (false negative, type II error), and 3497 were classified as 5 (true positive).\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "                <th></th>\n",
    "                <th>Non-5 Prediction</th>\n",
    "                <th>5 Prediction</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "                <th>Non-5 True Value</th>\n",
    "                <th>41582</th>\n",
    "                <th>1112</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "                <th>5 true value</th>\n",
    "                <th>709</th>\n",
    "                <th>3497</th>\n",
    "        </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Measuring Metrics</h3>\n",
    "\n",
    "**Precision: Measuring the accuracy of positive predictions**\n",
    "$$P = {TruePositives \\over TruePositives + FalsePositives}$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is usually used along with another metric called Recall. This is because precision itself is somewhat easy to pad. For example:\n",
    "\n",
    "`Imagine a model that always makes negative predictions, except for one where it is absolutely 100% positive about. This model would have 0 false positives and 1 true positive, a perfect precision socre of 1/1. However, this model is not very useful in the real world`\n",
    "\n",
    "**Recall - The True Positive Rate TPR**\n",
    "$$R = {TruePositives\\over TruePositives + FalseNegatives}$$\n",
    "\n",
    "Looking back at our table...\n",
    "<table>\n",
    "        <tr>\n",
    "                <th></th>\n",
    "                <th>Non-5 Prediction</th>\n",
    "                <th>5 Prediction</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "                <th>Non-5 True Value</th>\n",
    "                <th>41582 TRUE NEGATIVES</th>\n",
    "                <th>1112 FALSE POSITIVES</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "                <th>5 true value</th>\n",
    "                <th>709 FALSE NEGATIVES</th>\n",
    "                <th>3497 TRUE POSITIVES</th>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Whats important? Precision vs Recall</h4>\n",
    "\n",
    "It really depends on your situation. Say you trained a classifier to detect videos safe for kids. Would you:\n",
    "1. Want a classifier that classifies many safe videos as unsafe, but keeps only the safest videos? (HIGH PRECISION, not alot of false positives.)\n",
    "OR\n",
    "2. Want a classifier that classifies many unsafe videos as safe (HIGH RECALL, not alot of false negatives.)\n",
    "\n",
    "Obviously most people would want model number 1.\n",
    "\n",
    "What about another situation: Stopping shoplifters. Would you:\n",
    "1. Want a model that only catches people it is 100% sure are shoplifting? (HIGH PRECISION, low false positives)\n",
    "OR\n",
    "2. Want a model that assumes more people are shoplifting, even though they might be innocent (HIGH RECALL, low false negatives)\n",
    "\n",
    "Most store owners would probably want a model more like number 2.\n",
    "\n",
    "<h3>The F1 Score</h3>\n",
    "\n",
    "The F1 Score is the *harmonic mean* of precision and recall -> it combines them into a single metric. \n",
    "$$F_1 = {TruePositives \\over TruePositives + {FalseNeg + FalsePos \\over 2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 Score is high only if **both precision and recall are high**. Sometimes this is what you want, other times, as discussed above, you want to favor one over the other. It is up to your intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using SKLearn to calculate these metrics</h3>\n",
    "\n",
    "SKLearn has many prebuilt functions that allow us to calculate F1, Precision, and Recall very quickly. Lets go over them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7587329138641787, 0.8314312886352829)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "prec = precision_score(y_train_5, y_train_pred)\n",
    "rec = recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "prec, rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our model is correct about 75% of the time (prec = truepos/(truepos + falsepos))\n",
    "\n",
    "It also means that our model is correctly predicting about 83% of all 5s (recall = truepos/(truepos+falseneg))\n",
    "\n",
    "Now lets do F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934203062960862"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_train_5, y_train_pred)\n",
    "\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly, it might not be the best, but our model isn't too shabby.\n",
    "\n",
    "<h2>The Precision/Recall TradeOff</h2>\n",
    "We know from our examples earlier (kid friendly videos + shoplifting) that you can't really have it both ways. \n",
    "\n",
    "Increasing precision reduces recall, and increating recall reduces precision.\n",
    "\n",
    "To understand this tradeoff, we will take a look at *how* SGDClassifier makes its decisions.\n",
    "* For each instance, SGD computes a score based on a **decision function**\n",
    "    * If the score is greater than a threshold, it assigns the instance to the positive class, otherwise the negative class.\n",
    "\n",
    "In the figure below, assume that the decision threshold is at one of the arrows. We will calculate precision and recall for each of the decision thresholds. Notice how precision and recall are negatively correllated. \n",
    "\n",
    "<img src=\"./img/Decision Threshold.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente, SKLearn does not let you set the threshold directly. However, it does give you access to view the decision scores it makes.\n",
    "\n",
    "To do this, instead of calling `.predict()`, we can call `.decision_function()`. \n",
    "\n",
    "This will return a score for each instance instead of an actual prediction. We can then use this to test any threshold we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores = sgd_clf.decision_function(X_train)\n",
    "threshold = -200\n",
    "custom_thresh_pred = y_scores > threshold\n",
    "custom_thresh_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8388110198163364"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_thresh_pred_p = precision_score(y_train_5, custom_thresh_pred)\n",
    "custom_thresh_pred_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
